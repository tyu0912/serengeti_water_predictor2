{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datetime import date, datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import pathlib\n",
    "#from config import ACCESS_KEY,SECRET_KEY\n",
    "# import polling\n",
    "import boto3\n",
    "\n",
    "\n",
    "# Generating Order\n",
    "# API Key stored as an env variable\n",
    "PL_API_KEY = 'fa49aea30c534483bbf74f6ec9bc311a'\n",
    "PLANET_API_KEY = PL_API_KEY #os.getenv('PL_API_KEY')\n",
    "orders_v2_url = 'https://api.planet.com/compute/ops/orders/v2'\n",
    "\n",
    "# set up requests to work with api\n",
    "auth = HTTPBasicAuth(PLANET_API_KEY, '')\n",
    "headers = {'content-type': 'application/json'}\n",
    "\n",
    "\n",
    "item_type = \"PSScene4Band\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.7/site-packages/pyproj/crs/crs.py:55: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    }
   ],
   "source": [
    "waypoint_data = {\n",
    "    'Waypoint' : ['Orangi River', 'Mara River', 'Sand River', 'Grumeti River', 'Lake Masek', \n",
    "                  'Lake Magadi', 'Lake Empakaai', 'Lake Magadi 2', 'Mbalageti River', 'Ruwana River', 'Talek River'],\n",
    "    'latitude' : [-2.302313, -1.562928, -1.595733, -2.249034, -3.024818, -3.202214, -2.915433, -2.656248, -2.603015, -2.044819, -1.416096],\n",
    "    'longitude' : [34.830777, 34.997068, 35.069241, 34.486842, 35.038474, 35.536431, 35.841355, 34.788239, 34.720511, 34.230374, 35.097661]\n",
    "}\n",
    "\n",
    "\n",
    "waypoint_df = pd.DataFrame(waypoint_data)\n",
    "waypoint_gdf = gpd.GeoDataFrame(waypoint_df, geometry=gpd.points_from_xy(waypoint_df.longitude, waypoint_df.latitude))\n",
    "\n",
    "# Applying WGS84 to the CRS\n",
    "waypoint_gdf.crs = {'init' :'epsg:4326'} \n",
    "\n",
    "# Converting geodataframe to Meters from Lat/Long\n",
    "# Allows for square buffer to be applied (450m)\n",
    "point_gdf_m = waypoint_gdf.to_crs(epsg=3395)\n",
    "\n",
    "# Applying the buffer, cap_style = 3 --> Square Buffer\n",
    "buffer = point_gdf_m.buffer(450, cap_style=3)\n",
    "\n",
    "# Convert buffer back to WGS84 Lat/Long\n",
    "buffer_wgs84 = buffer.to_crs(epsg=4326)\n",
    "\n",
    "# Merging GDF and DF to get the Waypoint names\n",
    "joined_buffer_wgs84 = pd.concat([waypoint_df,buffer_wgs84], axis=1)\n",
    "joined_buffer_wgs84 = joined_buffer_wgs84.rename(columns = {0:'polygon'}).set_geometry('polygon')\n",
    "joined_buffer_wgs84_drop = joined_buffer_wgs84.drop(['geometry'], axis=1)\n",
    "joined_buffer_wgs84_json = joined_buffer_wgs84_drop.to_json()\n",
    "\n",
    "# transforming to json for inclusion into Planet API\n",
    "buffer_wgs84_json_parsed = json.loads(joined_buffer_wgs84_json)\n",
    "buffer_wgs84_json_api = buffer_wgs84_json_parsed['features']#[0]['geometry']['coordinates']\n",
    "\n",
    "\n",
    "today = datetime.isoformat(datetime.utcnow())+'Z'#(datetime.today())\n",
    "start_date = datetime.isoformat(datetime.utcnow() - timedelta(7)) + 'Z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Getting Image ID's for each waypoint that has the analytic_sr dataset \n",
    "# Having to ping the Planet V1 API to return the image id's for our required filter\n",
    "# Filter variables include: Center Coordinate, Date Range, Cloud Cover, Item Type and Asset Type\n",
    "\n",
    "\n",
    "def build_order(index):\n",
    "    geojson_geometry = {\n",
    "    \"type\": \"Point\",\n",
    "    \"coordinates\": [\n",
    "        index['properties']['longitude'], index['properties']['latitude']\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # get images that overlap with our AOI \n",
    "    geometry_filter = {\n",
    "      \"type\": \"GeometryFilter\",\n",
    "      \"field_name\": \"geometry\",\n",
    "      \"config\": geojson_geometry\n",
    "    }\n",
    "\n",
    "    date_range_filter = {\n",
    "      \"type\": \"DateRangeFilter\",\n",
    "      \"field_name\": \"acquired\",\n",
    "      \"config\": {\n",
    "        \"gte\": start_date,\n",
    "        \"lte\": today\n",
    "      }\n",
    "    }\n",
    "\n",
    "    # only get images which have <10% cloud coverage\n",
    "    cloud_cover_filter = {\n",
    "      \"type\": \"RangeFilter\",\n",
    "      \"field_name\": \"cloud_cover\",\n",
    "      \"config\": {\n",
    "        \"lte\": 0.1\n",
    "      }\n",
    "    }\n",
    "\n",
    "    # combine our geo, date, cloud filters\n",
    "    combined_filter = {\n",
    "      \"type\": \"AndFilter\",\n",
    "      \"config\": [geometry_filter, date_range_filter, cloud_cover_filter]\n",
    "    }\n",
    "    \n",
    "    # API request object\n",
    "    search_request = {\n",
    "        \"interval\": \"day\",\n",
    "        \"item_types\": [item_type],\n",
    "        \"asset_types\" : \"analytic_sr\",\n",
    "        \"filter\": combined_filter\n",
    "    }\n",
    "    \n",
    "    search_result = \\\n",
    "      requests.post(\n",
    "        'https://api.planet.com/data/v1/quick-search',\n",
    "    #     'https://api.planet.com/data/v2',\n",
    "        auth=HTTPBasicAuth(PLANET_API_KEY, ''),\n",
    "        json=search_request)\n",
    "\n",
    "    return search_result\n",
    "\n",
    "\n",
    "\n",
    "id_list = []\n",
    "\n",
    "for index in buffer_wgs84_json_api:\n",
    "    waypoint = index[\"properties\"][\"Waypoint\"]\n",
    "    order = build_order(index)\n",
    "    \n",
    "    time.sleep(3)\n",
    "    order = order.json()['features']\n",
    "    print(len(order))\n",
    "\n",
    "\n",
    "# appending Image ID to `joined_buffer_wgs84_drop_merge` if the analytic_sr is available\n",
    "# Will only return image id's that meet this requirement.\n",
    "    for i in order:\n",
    "        #print(order)\n",
    "        if \"assets.analytic_sr:download\" in order[0][\"_permissions\"]:\n",
    "            id_list.append((waypoint,order[0][\"id\"]))\n",
    "\n",
    "id_list = list(set(id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging image id's to the dataframe to maintain continuity\n",
    "\n",
    "image_ids = pd.DataFrame(np.asarray(id_list))\n",
    "image_ids.rename(columns = {0:'Waypoint', 1:'Image_ID'}, inplace = True) \n",
    "joined_buffer_wgs84_drop_merge = pd.merge(image_ids, joined_buffer_wgs84_drop, on='Waypoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting list of tuple polygons to list of lists polygons\n",
    "# This step is necessary to pull the Geometry from `joined_buffer_wgs84_drop_merge`\n",
    "# and convert to a list of lists...appending to `joined_buffer_wgs84_drop_merge`.\n",
    "\n",
    "def coord_lister(geom):\n",
    "    coords = list(geom.exterior.coords)\n",
    "    return (coords)\n",
    "\n",
    "coordinates = joined_buffer_wgs84_drop_merge.polygon.apply(coord_lister)\n",
    "res = []\n",
    "for poly in coordinates:\n",
    "    res_2 = list(map(list, poly)) \n",
    "    res.append(res_2)\n",
    "\n",
    "joined_buffer_wgs84_drop_merge['poly_list'] = res\n",
    "# joined_buffer_wgs84_drop_merge will be used as the basis for all remaining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the URLs to activate the images...prevents latency during download\n",
    "id0_url = []\n",
    "for id0 in joined_buffer_wgs84_drop_merge['Image_ID']:\n",
    "    id0_url_2 = 'https://api.planet.com/data/v1/item-types/{}/items/{}/assets'.format(item_type, id0)\n",
    "    id0_url.append(id0_url_2)\n",
    "\n",
    "# id0_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns JSON metadata for assets in this ID. \n",
    "# Learn more: planet.com/docs/reference/data-api/items-assets/#asset\n",
    "result = []\n",
    "for link in id0_url:\n",
    "#     print(link)\n",
    "    result1 = \\\n",
    "      requests.get(\n",
    "        link,\n",
    "        auth=HTTPBasicAuth(PLANET_API_KEY, '')\n",
    "      )\n",
    "    result.append(result1)\n",
    "\n",
    "# Parse out useful links\n",
    "\n",
    "links = []\n",
    "activation_link = []\n",
    "\n",
    "# Getting Result Links\n",
    "for r in result:\n",
    "    links1 = r.json()[u\"analytic_sr\"][\"_links\"]\n",
    "    links.append(links1)\n",
    "\n",
    "# Generating a list of activation links    \n",
    "for l in links:\n",
    "    activation_link1 = l[\"activate\"]\n",
    "    activation_link.append(activation_link1)\n",
    "activation_link\n",
    "\n",
    "# Request activation of the 'visual' asset:\n",
    "for a in activation_link:\n",
    "    activate_result = \\\n",
    "    requests.get(a,auth=HTTPBasicAuth(PLANET_API_KEY, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the order lists starting with the product information\n",
    "\n",
    "single_product = []\n",
    "for image_id in joined_buffer_wgs84_drop_merge['Image_ID']:\n",
    "    single_product_2 = [\n",
    "        {\n",
    "          'item_ids': [image_id], \n",
    "          'item_type': 'PSScene4Band',\n",
    "          'product_bundle': 'analytic_sr'\n",
    "        }\n",
    "    ]\n",
    "    single_product.append(single_product_2)\n",
    "# print(single_product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the clipping boundaries\n",
    "\n",
    "clip = []\n",
    "for polygon in joined_buffer_wgs84_drop_merge['poly_list']:\n",
    "    clip_aoi = {\n",
    "        'type':'Polygon',\n",
    "        'coordinates': [polygon] \n",
    "    }\n",
    "\n",
    "# define the clip tool\n",
    "    clip_2 = {\n",
    "        'clip': {\n",
    "            'aoi': clip_aoi\n",
    "        }\n",
    "    }\n",
    "    clip.append(clip_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create an order request with the clipping tool\n",
    "request_clip = []\n",
    "\n",
    "for p, c in zip(single_product, clip):\n",
    "    request_clip_2 = {\n",
    "        'name': 'just clip',\n",
    "        'products': p, #single_product,\n",
    "        'tools': [c]\n",
    "    }\n",
    "    request_clip.append(request_clip_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [202]>\n",
      "710e2691-ea3b-46a1-a98e-8c88d2f2485d\n",
      "<Response [202]>\n",
      "2b17d9c9-9ccb-44b7-90ff-732a8c083821\n",
      "<Response [202]>\n",
      "1736d836-a48b-4476-8996-fb0bd5456a9d\n",
      "<Response [202]>\n",
      "5885147b-c259-4f34-96ea-95d3e4f788fd\n",
      "<Response [429]>\n",
      "1a132e22-a92d-4162-86ea-270d89bd74b5\n",
      "<Response [202]>\n",
      "5055e6a5-e220-48e0-af6c-dd72c82b066c\n",
      "<Response [202]>\n",
      "0efbf449-a4b6-45e9-9880-356cd90e28b6\n",
      "<Response [429]>\n",
      "962c435c-e3e3-4169-b79b-4c54dd088b37\n",
      "<Response [202]>\n",
      "c1e4a175-5271-44ad-822c-377d7137bc6a\n"
     ]
    }
   ],
   "source": [
    "# Creating the url for clipping \n",
    "def place_order(request, auth):\n",
    "    response = requests.post(orders_v2_url, data=json.dumps(request), auth=auth, headers=headers)\n",
    "    print(response)\n",
    "    \n",
    "    if response.status_code == 429:\n",
    "        time.sleep(3)\n",
    "        response = requests.post(orders_v2_url, data=json.dumps(request), auth=auth, headers=headers)\n",
    "    \n",
    "        if not response.ok:\n",
    "            raise Exception(response.content)\n",
    "\n",
    "    order_id = response.json()['id']\n",
    "    print(order_id)\n",
    "    \n",
    "    order_url = orders_v2_url + '/' + order_id\n",
    "    \n",
    "    return order_url\n",
    "\n",
    "\n",
    "order_url = []\n",
    "for req_c in request_clip:\n",
    "    order_url2 = place_order(request_clip[1], auth)\n",
    "    order_url.append(order_url2)\n",
    "\n",
    "# order_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time.sleep(600)\n",
    "\n",
    "def poll_for_success(order_url, auth, num_loops=50, sleep_time=10):\n",
    "    count = 0\n",
    "    while(count < num_loops):\n",
    "        r = requests.get(order_url, auth=auth)\n",
    "        response = r.json()\n",
    "        state = response['state']\n",
    "        \n",
    "        print(f'{count * sleep_time}: {state}')\n",
    "        success_states = ['success', 'partial']\n",
    "        \n",
    "        if state == 'failed':\n",
    "            raise Exception(response)\n",
    "        elif state in success_states:\n",
    "            break\n",
    "        \n",
    "        time.sleep(sleep_time)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [202]>\n",
      "2ab69423-8a89-4c0a-9feb-5d0309ba169a\n",
      "0: queued\n",
      "10: running\n",
      "20: running\n",
      "30: running\n",
      "40: running\n",
      "50: running\n",
      "60: running\n",
      "70: running\n",
      "80: running\n",
      "90: running\n",
      "100: running\n",
      "110: running\n",
      "120: running\n",
      "130: running\n",
      "140: running\n",
      "150: running\n",
      "160: running\n",
      "170: running\n",
      "180: running\n",
      "190: running\n",
      "200: running\n",
      "210: running\n",
      "220: running\n",
      "230: running\n",
      "240: running\n",
      "250: running\n",
      "260: running\n",
      "270: running\n",
      "280: running\n",
      "290: running\n",
      "300: running\n",
      "310: running\n",
      "320: running\n",
      "330: running\n",
      "340: running\n",
      "350: running\n",
      "360: running\n",
      "370: running\n",
      "380: running\n",
      "390: running\n",
      "400: running\n",
      "410: running\n",
      "420: running\n",
      "430: running\n",
      "440: running\n",
      "450: running\n",
      "460: running\n",
      "470: running\n",
      "480: running\n",
      "490: running\n",
      "<Response [202]>\n",
      "e15601bb-5627-4ea9-a2e1-a6adad578470\n",
      "0: queued\n",
      "10: queued\n",
      "20: queued\n",
      "30: running\n",
      "40: running\n",
      "50: running\n",
      "60: running\n",
      "70: running\n",
      "80: running\n",
      "90: running\n",
      "100: running\n",
      "110: running\n",
      "120: running\n",
      "130: running\n",
      "140: running\n",
      "150: running\n",
      "160: running\n",
      "170: running\n",
      "180: running\n",
      "190: running\n",
      "200: running\n",
      "210: running\n",
      "220: running\n",
      "230: running\n",
      "240: running\n",
      "250: running\n",
      "260: running\n",
      "270: running\n",
      "280: running\n",
      "290: running\n",
      "300: running\n",
      "310: running\n",
      "320: running\n",
      "330: running\n",
      "340: running\n",
      "350: running\n",
      "360: running\n",
      "370: running\n",
      "380: running\n",
      "390: running\n"
     ]
    }
   ],
   "source": [
    "run_clip = True\n",
    "\n",
    "clip_order_url = []\n",
    "if run_clip:\n",
    "    for c in order_url:\n",
    "        time.sleep(20)\n",
    "        clip_order_url2 = place_order(request_clip[1], auth)\n",
    "        poll_for_success(clip_order_url2,auth)\n",
    "        clip_order_url.append(clip_order_url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "5 items to download\n",
      "downloading 1ae3d33f-1499-4c77-8066-bbe03385dfec/1/manifest.json to data/1ae3d33f-1499-4c77-8066-bbe03385dfec/1/manifest.json\n",
      "downloading 1ae3d33f-1499-4c77-8066-bbe03385dfec/1/files/20200312_064310_1053_3B_AnalyticMS_DN_udm_clip.tif to data/1ae3d33f-1499-4c77-8066-bbe03385dfec/1/files/20200312_064310_1053_3B_AnalyticMS_DN_udm_clip.tif\n",
      "downloading 1ae3d33f-1499-4c77-8066-bbe03385dfec/1/files/20200312_064310_1053_metadata.json to data/1ae3d33f-1499-4c77-8066-bbe03385dfec/1/files/20200312_064310_1053_metadata.json\n",
      "downloading 1ae3d33f-1499-4c77-8066-bbe03385dfec/1/files/20200312_064310_1053_3B_AnalyticMS_SR_clip.tif to data/1ae3d33f-1499-4c77-8066-bbe03385dfec/1/files/20200312_064310_1053_3B_AnalyticMS_SR_clip.tif\n",
      "downloading 1ae3d33f-1499-4c77-8066-bbe03385dfec/1/files/20200312_064310_1053_3B_AnalyticMS_metadata_clip.xml to data/1ae3d33f-1499-4c77-8066-bbe03385dfec/1/files/20200312_064310_1053_3B_AnalyticMS_metadata_clip.xml\n",
      "<Response [200]>\n",
      "5 items to download\n",
      "downloading 3eca6b36-6955-4c51-a825-1fea21d71714/1/manifest.json to data/3eca6b36-6955-4c51-a825-1fea21d71714/1/manifest.json\n",
      "downloading 3eca6b36-6955-4c51-a825-1fea21d71714/1/files/20200312_064310_1053_3B_AnalyticMS_metadata_clip.xml to data/3eca6b36-6955-4c51-a825-1fea21d71714/1/files/20200312_064310_1053_3B_AnalyticMS_metadata_clip.xml\n",
      "downloading 3eca6b36-6955-4c51-a825-1fea21d71714/1/files/20200312_064310_1053_3B_AnalyticMS_SR_clip.tif to data/3eca6b36-6955-4c51-a825-1fea21d71714/1/files/20200312_064310_1053_3B_AnalyticMS_SR_clip.tif\n",
      "downloading 3eca6b36-6955-4c51-a825-1fea21d71714/1/files/20200312_064310_1053_metadata.json to data/3eca6b36-6955-4c51-a825-1fea21d71714/1/files/20200312_064310_1053_metadata.json\n",
      "downloading 3eca6b36-6955-4c51-a825-1fea21d71714/1/files/20200312_064310_1053_3B_AnalyticMS_DN_udm_clip.tif to data/3eca6b36-6955-4c51-a825-1fea21d71714/1/files/20200312_064310_1053_3B_AnalyticMS_DN_udm_clip.tif\n",
      "<Response [200]>\n",
      "5 items to download\n",
      "downloading fb4be382-28b1-4512-b88b-d8bfe0a86100/1/manifest.json to data/fb4be382-28b1-4512-b88b-d8bfe0a86100/1/manifest.json\n",
      "downloading fb4be382-28b1-4512-b88b-d8bfe0a86100/1/files/20200312_064310_1053_3B_AnalyticMS_metadata_clip.xml to data/fb4be382-28b1-4512-b88b-d8bfe0a86100/1/files/20200312_064310_1053_3B_AnalyticMS_metadata_clip.xml\n",
      "downloading fb4be382-28b1-4512-b88b-d8bfe0a86100/1/files/20200312_064310_1053_metadata.json to data/fb4be382-28b1-4512-b88b-d8bfe0a86100/1/files/20200312_064310_1053_metadata.json\n",
      "downloading fb4be382-28b1-4512-b88b-d8bfe0a86100/1/files/20200312_064310_1053_3B_AnalyticMS_SR_clip.tif to data/fb4be382-28b1-4512-b88b-d8bfe0a86100/1/files/20200312_064310_1053_3B_AnalyticMS_SR_clip.tif\n",
      "downloading fb4be382-28b1-4512-b88b-d8bfe0a86100/1/files/20200312_064310_1053_3B_AnalyticMS_DN_udm_clip.tif to data/fb4be382-28b1-4512-b88b-d8bfe0a86100/1/files/20200312_064310_1053_3B_AnalyticMS_DN_udm_clip.tif\n",
      "<Response [200]>\n",
      "5 items to download\n",
      "downloading 518a8be2-f547-4d26-a44b-6132b6aac593/1/manifest.json to data/518a8be2-f547-4d26-a44b-6132b6aac593/1/manifest.json\n",
      "downloading 518a8be2-f547-4d26-a44b-6132b6aac593/1/files/20200312_064310_1053_3B_AnalyticMS_DN_udm_clip.tif to data/518a8be2-f547-4d26-a44b-6132b6aac593/1/files/20200312_064310_1053_3B_AnalyticMS_DN_udm_clip.tif\n",
      "downloading 518a8be2-f547-4d26-a44b-6132b6aac593/1/files/20200312_064310_1053_3B_AnalyticMS_metadata_clip.xml to data/518a8be2-f547-4d26-a44b-6132b6aac593/1/files/20200312_064310_1053_3B_AnalyticMS_metadata_clip.xml\n",
      "downloading 518a8be2-f547-4d26-a44b-6132b6aac593/1/files/20200312_064310_1053_3B_AnalyticMS_SR_clip.tif to data/518a8be2-f547-4d26-a44b-6132b6aac593/1/files/20200312_064310_1053_3B_AnalyticMS_SR_clip.tif\n",
      "downloading 518a8be2-f547-4d26-a44b-6132b6aac593/1/files/20200312_064310_1053_metadata.json to data/518a8be2-f547-4d26-a44b-6132b6aac593/1/files/20200312_064310_1053_metadata.json\n",
      "<Response [200]>\n",
      "5 items to download\n",
      "downloading aaf1ad49-ede0-40ff-85fc-190e401e0afb/1/manifest.json to data/aaf1ad49-ede0-40ff-85fc-190e401e0afb/1/manifest.json\n",
      "downloading aaf1ad49-ede0-40ff-85fc-190e401e0afb/1/files/20200312_064310_1053_3B_AnalyticMS_metadata_clip.xml to data/aaf1ad49-ede0-40ff-85fc-190e401e0afb/1/files/20200312_064310_1053_3B_AnalyticMS_metadata_clip.xml\n",
      "downloading aaf1ad49-ede0-40ff-85fc-190e401e0afb/1/files/20200312_064310_1053_metadata.json to data/aaf1ad49-ede0-40ff-85fc-190e401e0afb/1/files/20200312_064310_1053_metadata.json\n",
      "downloading aaf1ad49-ede0-40ff-85fc-190e401e0afb/1/files/20200312_064310_1053_3B_AnalyticMS_DN_udm_clip.tif to data/aaf1ad49-ede0-40ff-85fc-190e401e0afb/1/files/20200312_064310_1053_3B_AnalyticMS_DN_udm_clip.tif\n",
      "downloading aaf1ad49-ede0-40ff-85fc-190e401e0afb/1/files/20200312_064310_1053_3B_AnalyticMS_SR_clip.tif to data/aaf1ad49-ede0-40ff-85fc-190e401e0afb/1/files/20200312_064310_1053_3B_AnalyticMS_SR_clip.tif\n"
     ]
    }
   ],
   "source": [
    "# Downloading from each clip order url\n",
    "def download_order(order_url, auth, overwrite=False):\n",
    "    r = requests.get(order_url, auth=auth)\n",
    "    print(r)\n",
    "\n",
    "    response = r.json()\n",
    "    results = response['_links']['results']\n",
    "    results_urls = [r['location'] for r in results]\n",
    "    results_names = [r['name'] for r in results]\n",
    "    results_paths = [pathlib.Path(os.path.join('data', n)) for n in results_names]\n",
    "    print('{} items to download'.format(len(results_urls)))\n",
    "    \n",
    "    for url, name, path in zip(results_urls, results_names, results_paths):\n",
    "        if overwrite or not path.exists():\n",
    "            print('downloading {} to {}'.format(name, path))\n",
    "            r = requests.get(url, allow_redirects=True)\n",
    "            path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            open(path, 'wb').write(r.content)\n",
    "        else:\n",
    "            print('{} already exists, skipping {}'.format(path, name))\n",
    "            \n",
    "    return dict(zip(results_names, results_paths))\n",
    "\n",
    "\n",
    "# Process sleeping to allow for activation, staging, and processing of imagery\n",
    "\n",
    "\n",
    "# Downloading the orders\n",
    "for clip_order in clip_order_url:\n",
    "    download_order(clip_order, auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3_resource = boto3.resource('s3')\n",
    "# s3_resource.meta.client.upload_file(\n",
    "#     Filename='/Users/jasonabaker/W210/Project/Planet_API/Waypoint_Scripts_2/data/e59ba56a-c72a-4f49-b680-273e243f8fd1/1/files/20200305_163004_0f44_3B_AnalyticMS_SR_clip.tif', Bucket='w210-planet-data-api',\n",
    "#     Key= '20200305_163004_0f44_3B_AnalyticMS_SR_clip.tif')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
